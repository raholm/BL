---
title: "Bayesian Learning"
subtitle: Lab 2
author: "Emil K Svensson and Rasmus Holm"
date: '`r Sys.Date()`'
output:
    pdf_document:
        includes:
            in_header: styles.sty
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Question 1

```{r}
temp <- read.table("../data/TempLinkoping2016.txt", header=T)

mod <- lm(temp ~ time + I(time^2), data=temp)
```

```{r}
plot(temp$time, temp$temp)
lines(sort(temp$time), fitted(mod)[order(temp$time)], col='red', type='l')
```

Prior

\begin{align*}
\sigma^2 &\sim \text{Inv -- } \chi^2(\nu_{0}, \sigma_{0}^{2}) \\
\beta | \sigma^2 &\sim \text{N}(\mu_{0}, \sigma^2 \Omega_{0}^{-1})
\end{align*}

Likelihood

\begin{align*}
\textbf{y}| \beta, \sigma^2, \textbf{X} &\sim \text{N}(\textbf{X} \beta, \sigma^2 I_{n})
\end{align*}

Posterior

\begin{align*}
\sigma^2 | \textbf{y} &\sim \text{Inv -- } \chi^2(\nu_{n}, \sigma_{n}^{2}) \\
\beta | \sigma^2, \textbf{y} &\sim \text{N}(\mu_{n}, \sigma^2 \Omega_{n}^{-1}) \\
\intertext{where}
\mu_{n} &= (\textbf{X}^\intercal \textbf{X} + \Omega_0)^{-1} (\textbf{X}^\intercal \textbf{X} \hat{\beta} + \Omega_{0} \mu_{0}) \\
\Omega_{n} &= \textbf{X}^\intercal \textbf{X} + \Omega_{0} \\
\nu_{n} &= \nu_{0} + n \\
\nu_{n} \sigma^{2}_{n} &= \nu_{0} \sigma^2_0 + (\textbf{y}^\intercal \textbf{y} + \mu^{\intercal}_{0} \Omega_0 \mu_0 - \mu^{\intercal}_{n} \Omega_n \mu_n)
\end{align*}

## a)

```{r}
mu0 <- c(0, 0, 0)
omega0 <- diag(3) * 0.5
nu0 <- 1
sigmasq0 <- 20

hyperparams <- list(mu=mu0, omega=omega0, nu=nu0, sigmasq=sigmasq0)
```

## b)

```{r}
library(geoR)
library(MASS)

time <- data.frame(rep(1,nrow(temp)), temp$time, temp$time^2)
mtime <- as.matrix(time)
mtemp <- matrix(temp$temp, ncol = 1)

prior_estimate <- function(data, params){
    sigmasq  <- rinvchisq( n = 1, df = params$nu, scale = params$sigmasq)
    betacoef <- mvrnorm(n = 1, mu = params$mu, Sigma = sigmasq * solve(params$omega) )

    data %*% betacoef
}
```

```{r}
plot(temp$time, temp$temp)

x <- sort(temp$time)

set.seed(12345)

for (i in 1:20){
    y <- prior_estimate(mtime, hyperparams)[order(temp$time)]
    lines(x, y, col='red', type='l')
}
```

```{r}
set.seed(12345)

x <- sort(temp$time)
y <- rowMeans(sapply(1:1000, function(x) prior_estimate(mtime, hyperparams)[order(temp$time)]))

plot(temp$time, temp$temp)
lines(x, y, col='red', type='l')
```

## c)

```{r}
posterior_param_sample <- function(X, y, hyperparams){
    XX <- t(X) %*% X
    betahat <- solve(XX) %*% t(X) %*% y
    mun <- solve(XX + hyperparams$omega) %*%
        (XX %*% betahat + hyperparams$omega %*% hyperparams$mu)
    omegan <- XX + hyperparams$omega
    nun <- hyperparams$nu + nrow(X)
    nunsigmasqn <- hyperparams$nu * hyperparams$sigmasq +
        (t(y) %*% y +
         t(hyperparams$mu) %*% hyperparams$omega %*% hyperparams$mu -
         t(mun) %*% omegan %*% mun )
    sigmasqn <- nunsigmasqn / nun

    sigmasq  <- rinvchisq(n = 1, df=nun, scale=sigmasqn)
    beta <- mvrnorm(n = 1, mu = mun, Sigma = as.numeric(sigmasq) * solve(omegan))

    list(beta = beta, sigmasq = sigmasq)
}

posterior_estimate <- function(X, y, params){
    ests <- posterior_param_sample(X, y, params)
    X %*% ests$beta
}
```

```{r}
plot(temp$time, temp$temp)

set.seed(12345)

idx <- order(temp$time)
x <- temp$time[idx]
y <- posterior_estimate(mtime, mtemp, hyperparams)[idx]

lines(x, y, col='red', type='l')
```

```{r}
set.seed(12345)

ests <- sapply(1:1000, FUN = function(x) posterior_estimate(mtime, mtemp, hyperparams))
cred_interval <- apply(ests, MARGIN = 1, quantile, probs = c(0.05, 0.95))

idx <- order(temp$time)
x <- temp$time[idx]
y1 <- rowMeans(ests)[idx]
y2 <- cred_interval[1,][idx]
y3 <- cred_interval[2,][idx]

plot(temp$time, temp$temp)
lines(x, y1, col='red', type='l')
lines(x, y2, col='blue', type='l')
lines(x, y3, col='blue', type='l')
```

## d)

```{r}
set.seed(12345)

betas <- sapply(1:1000, FUN = function(x) posterior_param_sample(mtime, mtemp, hyperparams)$beta)
hot <- mean(-betas[2,] / (2 * betas[3,]))
hot * 366 # July 27, 2016 (Wed)
```


## e)
Set $\mu_0$ to zeros and a high $\Omega_0$ that expresses a high degree of certainty in our prior.

\newpage

# Question 2

```{r}
women <- read.table("../data/WomenWorks.txt", header = TRUE)
```

## a)

```{r}
glmModel <- glm(Work ~ 0 + ., data = women, family = binomial)

glmModel
summary(glmModel)
```

## b)

## c)
